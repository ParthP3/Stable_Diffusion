{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESNET 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "path = 'data/PokemonData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])mean  = np.array([0.458, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "\n",
    "images = datasets.ImageFolder(path, data_transforms)\n",
    "image_classes = images.classes\n",
    "#print(image_classes)\n",
    "train_img, val_img, test_img = torch.utils.data.random_split(images, [0.7, 0.1, 0.2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_img, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=val_img, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_img, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "dataloaders = {\n",
    "   'train': train_loader,\n",
    "   'valid': valid_loader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_loader),\n",
    "    'valid': len(valid_loader)    \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class subResNet(nn.Module):\n",
    "    def __init__(self, channel1, channel2, type = 0, identity_downsample = None, stride = 1):\n",
    "        super(subResNet, self).__init__()\n",
    "        if type == 0:\n",
    "            self.conv1 = nn.Conv2d(channel2, channel2, 1, stride = stride, padding = 0)\n",
    "        elif type == 1:\n",
    "            self.conv1 = nn.Conv2d(channel2*4, channel2, 1, stride = stride, padding = 0)\n",
    "        elif type == 2:\n",
    "            self.conv1 = nn.Conv2d(channel2*2, channel2, 1, stride = stride, padding = 0)\n",
    "\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(channel2)\n",
    "        self.conv2 = nn.Conv2d(channel2, channel2, 3, stride = 1, padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(channel2)\n",
    "        self.conv3 = nn.Conv2d(channel2, channel2*4, 1, stride = 1, padding = 0)\n",
    "        self.bn3 = nn.BatchNorm2d(channel2*4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        if self.identity_downsample != None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, layers, channels, classes):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, 64, 7, stride = 2, padding  = 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "\n",
    "        self.layer1 = self.make_layer(layers[0], 64, 1)\n",
    "        self.layer2 = self.make_layer(layers[1], 128, 2)\n",
    "        self.layer3 = self.make_layer(layers[2], 256, 2)\n",
    "        self.layer4 = self.make_layer(layers[3], 512, 2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(2048, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "    def make_layer(self, num_blocks, in_channels, stride):\n",
    "        layer = []\n",
    "        identity_ds = None\n",
    "        if stride != 1:\n",
    "            identity_ds = nn.Sequential(\n",
    "                nn.Conv2d(in_channels*2, in_channels*4, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(in_channels*4),\n",
    "            )\n",
    "        else:\n",
    "            identity_ds = nn.Sequential(\n",
    "                nn.Conv2d(64, 256, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "            )\n",
    "        if in_channels == 64:\n",
    "            layer.append(subResNet(in_channels, in_channels, 0, identity_downsample=identity_ds, stride = stride))\n",
    "        else:\n",
    "            layer.append(subResNet(in_channels, in_channels, 2, identity_downsample=identity_ds, stride = stride))\n",
    "            \n",
    "        for i in range(1, num_blocks):\n",
    "            layer.append(subResNet(in_channels, in_channels, 1))\n",
    "\n",
    "        return nn.Sequential(*layer)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(layers = [3, 4, 6, 3], channels = 3, classes = len(image_classes)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate, weight_decay = 0.0001, momentum = 0.9)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print('-'*10)\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "        n_total = 0.0\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, pred = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(pred == labels.data)\n",
    "            n_total += outputs.shape[0]\n",
    "        if phase == 'train':\n",
    "            scheduler.step()\n",
    "        epoch_loss = running_loss / (n_total)\n",
    "        epoch_acc = running_corrects.double() / (n_total)\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        if phase == 'valid' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    print()\n",
    "\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print(f'Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s')\n",
    "print(f'Best accuracy: {best_acc:4f}')\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(image_classes))]\n",
    "    n_class_samples = [0 for i in range(len(image_classes))]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {image_classes[i]}: {acc} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Dec  8 2022, 14:47:55) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a19944f9d21de8215923c9ccd2626030137432aa66b78922113a3bfd107c2f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
